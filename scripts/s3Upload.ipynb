{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272806d2-d273-498e-a68b-d124c429cad9",
   "metadata": {},
   "source": [
    "## Upload files to S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0be4704-8dca-4be0-9fcd-ca7cc590716c",
   "metadata": {},
   "source": [
    "### Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbcb75a-2a74-47c5-9138-69194d34dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04949b28-0206-4aef-b7b7-39de27adf9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('../config/.env',override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38259b65-c438-4bdf-9459-3c4c7f3ee493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadenv():\n",
    "    s3_bucket_name = os.getenv(\"s3_bucket_name\")\n",
    "    s3_pypdf = os.getenv(\"s3_pypdf\")\n",
    "    s3_grobid = os.getenv(\"s3_grobid\")\n",
    "    access_key = os.getenv(\"access_key\")\n",
    "    secret_key = os.getenv(\"secret_key\")\n",
    "    region = os.getenv(\"region\")\n",
    "    return s3_bucket_name, s3_pypdf, s3_grobid, access_key, secret_key, region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2d90f5-d539-4fc7-a189-cdf3f85120ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket_name, s3_pypdf, s3_grobid, access_key, secret_key, region = loadenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f6034-ee81-477a-91f2-7453419916a3",
   "metadata": {},
   "source": [
    "### Function to upload .txt files to a particular folder inside s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed825a94-6a01-4ed1-9405-ccc7e5ef3b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_text_files_to_s3_folder(local_path, bucket_name, s3_folder):\n",
    "    # Create an S3 client\n",
    "    s3 = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key, region_name = region)\n",
    "\n",
    "    # Iterate through all files in the local directory\n",
    "    for filename in os.listdir(local_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            local_file_path = os.path.join(local_path, filename)\n",
    "            s3_object_key = f\"{s3_folder}/{filename}\"\n",
    "\n",
    "            # Check if the file already exists in S3\n",
    "            try:\n",
    "                s3.head_object(Bucket=bucket_name, Key=s3_object_key)\n",
    "                print(f\"File {filename} already exists in S3. Overwriting...\")\n",
    "            except Exception as e:\n",
    "                # If the file doesn't exist, upload it\n",
    "                try:\n",
    "                    s3.upload_file(local_file_path, bucket_name, s3_object_key)\n",
    "                    print(f\"File {filename} uploaded successfully to S3: s3://{bucket_name}/{s3_object_key}\")\n",
    "                except Exception as upload_error:\n",
    "                    print(f\"Error uploading file {filename} to S3: {upload_error}\")\n",
    "        elif filename == \"metadata_output.csv\":\n",
    "            local_file_path = os.path.join(local_path, filename)\n",
    "            s3_object_key = f\"{s3_folder}/{filename}\"\n",
    "\n",
    "            # Check if the file already exists in S3\n",
    "            try:\n",
    "                s3.head_object(Bucket=bucket_name, Key=s3_object_key)\n",
    "                print(f\"File {filename} already exists in S3. Overwriting...\")\n",
    "            except Exception as e:\n",
    "                # If the file doesn't exist, upload it\n",
    "                try:\n",
    "                    s3.upload_file(local_file_path, bucket_name, s3_object_key)\n",
    "                    print(f\"File {filename} uploaded successfully to S3: s3://{bucket_name}/{s3_object_key}\")\n",
    "                except Exception as upload_error:\n",
    "                    print(f\"Error uploading file {filename} to S3: {upload_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d74c41c-05be-46f0-827a-970f06f95300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_text_files_to_s3_root(local_path, s3_bucket_name):\n",
    "    # Create an S3 client\n",
    "    s3 = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key, region_name = region)\n",
    "\n",
    "    # List all files in the local path\n",
    "    local_files = os.listdir(local_path)\n",
    "\n",
    "    for file_name in local_files:\n",
    "        if file_name == '224_links.txt':  # Upload only text files, adjust the condition based on your file types\n",
    "            local_file_path = os.path.join(local_path, file_name)\n",
    "\n",
    "            # Specify the S3 key (file path within the bucket)\n",
    "            s3_key = file_name  # This will upload directly to the root of the S3 bucket\n",
    "\n",
    "            # Upload the file to S3\n",
    "            try:\n",
    "                s3.upload_file(local_file_path, s3_bucket_name, s3_key)\n",
    "                print(f\"Successfully uploaded {file_name} to S3 bucket {s3_bucket_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error uploading {file_name} to S3: {e}\")\n",
    "        elif file_name == 'metadata_output.csv':  # Upload only text files, adjust the condition based on your file types\n",
    "            local_file_path = os.path.join(local_path, file_name)\n",
    "\n",
    "            # Specify the S3 key (file path within the bucket)\n",
    "            s3_key = file_name  # This will upload directly to the root of the S3 bucket\n",
    "\n",
    "            # Upload the file to S3\n",
    "            try:\n",
    "                s3.upload_file(local_file_path, s3_bucket_name, s3_key)\n",
    "                print(f\"Successfully uploaded {file_name} to S3 bucket {s3_bucket_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error uploading {file_name} to S3: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6431bea-3fbb-4263-b392-1147a8d8546c",
   "metadata": {},
   "source": [
    "### Uploading .txt files generated using PyPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3604be20-f0a4-4f59-8c5f-b4cfc35c6c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File PyPDF_RR_2024_l1_combined.txt already exists in S3. Overwriting...\n",
      "File PyPDF_RR_2024_l2_combined.txt already exists in S3. Overwriting...\n",
      "File PyPDF_RR_2024_l3_combined.txt already exists in S3. Overwriting...\n"
     ]
    }
   ],
   "source": [
    "local_path = '../sample_output/PyPDF'\n",
    "\n",
    "# Upload only new text files or overwrite existing ones in the specified S3 folder\n",
    "upload_text_files_to_s3_folder(local_path, s3_bucket_name, s3_pypdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d4429d-bd47-453c-96f6-1f2112ad4bf4",
   "metadata": {},
   "source": [
    "### Uploading .txt files generated using Grobid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25bb9cfc-665a-4fe0-b27f-25376fa7521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Grobid_RR_2024_l1_combined.txt already exists in S3. Overwriting...\n",
      "File Grobid_RR_2024_l2_combined.txt already exists in S3. Overwriting...\n",
      "File Grobid_RR_2024_l3_combined.txt already exists in S3. Overwriting...\n"
     ]
    }
   ],
   "source": [
    "local_path = '../sample_output/Grobid'\n",
    "\n",
    "# Upload only new text files or overwrite existing ones in the specified S3 folder\n",
    "upload_text_files_to_s3_folder(local_path, s3_bucket_name, s3_grobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761132f-9ac0-4bf4-b48c-f6a5cf88f7a4",
   "metadata": {},
   "source": [
    "### Uploading metadata.csv and 224_Links.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a97450-d548-41fe-a28c-65e891137fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded 224_links.txt to S3 bucket cfa-pdfs\n",
      "Successfully uploaded metadata_output.csv to S3 bucket cfa-pdfs\n"
     ]
    }
   ],
   "source": [
    "local_path = '../sample_output/'\n",
    "upload_text_files_to_s3_root(local_path, s3_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0721e-c3e6-4a33-b1a8-a3911792eb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
