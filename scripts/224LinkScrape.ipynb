{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "026070aa-9b56-41af-b035-fb501800577f",
   "metadata": {},
   "source": [
    "## Scraping 224 URL's from Finance Institute's Webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db41171-d0f3-47ac-81ec-75269648e847",
   "metadata": {},
   "source": [
    "### Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "718265ba-d258-4bdb-921b-d0af7c4b298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d554de1-8cff-4898-bced-874c09db9ca4",
   "metadata": {},
   "source": [
    "### Scrape function to extract links which comes as part of `CoveoResultLink` class under anchor tag in the given webpage and save those to a .txt file\n",
    "\n",
    "- Strategy used involves edge browser webdriver to make the beutiful soup scraper wait for a certain amount of time before scraping as the links which needs to be extracted loads dynamically over the page after a particular Javascript snippet gets successfully executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "249b86ae-acb9-48de-a0b1-9114eed113aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_coveo_links(url):\n",
    "    # Set up the WebDriver with the command line flag for Edge\n",
    "    edge_options = webdriver.EdgeOptions()\n",
    "    edge_options.add_argument('--enable-chrome-browser-cloud-management')\n",
    "\n",
    "    driver = webdriver.Edge(options=edge_options)\n",
    "\n",
    "    try:\n",
    "        # Make a request using Selenium\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the dynamic content to load (you may need to adjust the sleep duration)\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Get the page source after dynamic content has loaded\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Find all the links with class 'coveo'\n",
    "        coveo_links = soup.find_all('a', class_='CoveoResultLink')\n",
    "\n",
    "        # Extract and write the href attribute of each coveo link to a file\n",
    "        with open(\"../sample_output/224_links.txt\", \"a\") as file:\n",
    "            for link in coveo_links:\n",
    "                href = link.get('href')\n",
    "                if href:\n",
    "                    file.write(href + '\\n')\n",
    "\n",
    "        # Print the total number of coveo links\n",
    "        print(f\"Total number of Coveo class links: {len(coveo_links)}\")\n",
    "        print(\"Coveo class links saved to '224_links.txt'\")\n",
    "\n",
    "    finally:\n",
    "        # Close the WebDriver in a 'finally' block to ensure it is closed even if an exception occurs\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef8bea-e6f8-43cd-a3e6-b5ecbb475148",
   "metadata": {},
   "source": [
    "### Looping to scrape links page by page taking `pagination` into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22b98bfb-1f98-45aa-b941-7f691e79bbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file '../sample_output/224_links.txt' has been emptied.\n",
      "Total number of Coveo class links: 24\n",
      "Coveo class links saved to '224_links.txt'\n",
      "Total number of Coveo class links: 100\n",
      "Coveo class links saved to '224_links.txt'\n",
      "Total number of Coveo class links: 100\n",
      "Coveo class links saved to '224_links.txt'\n"
     ]
    }
   ],
   "source": [
    "count = 2\n",
    "\n",
    "file_path = '../sample_output/224_links.txt'  # Replace with the actual file path\n",
    "## Create/overwrite the file to empty it\n",
    "try:\n",
    "    # Open the file in write mode ('w') or truncate mode ('w+')\n",
    "    with open(file_path, 'w+', encoding='utf-8'):\n",
    "        pass  # The 'pass' statement does nothing, effectively emptying the file\n",
    "\n",
    "    print(f\"The file '{file_path}' has been emptied.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' does not exist.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "while(count>=0):\n",
    "    url = f\"https://www.cfainstitute.org/en/membership/professional-development/refresher-readings#first={count*100}&sort=%40refreadingcurriculumyear%20descending&numberOfResults=100\"\n",
    "    scrape_coveo_links(url)\n",
    "    count = count - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f19310-9f7f-42ff-b1d3-9082ace1ec66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
